{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results.\n",
    "\n",
    "Answer = Analysis of Variance (ANOVA) is a statistical technique used to compare means of three or more groups to determine whether there are any statistically significant differences among them. However, ANOVA makes certain assumptions, and violations of these assumptions can impact the validity of the results. The main assumptions for ANOVA are:\n",
    "\n",
    "Independence of Observations:\n",
    "\n",
    "Assumption: The observations within each group are independent of each other.\n",
    "Violation Example: If the observations within a group are correlated or dependent, it can lead to inaccurate results. For example, repeated measures on the same subjects without proper consideration of the dependence structure.\n",
    "Normality of Residuals:\n",
    "\n",
    "Assumption: The residuals (the differences between observed and predicted values) are normally distributed.\n",
    "Violation Example: If the residuals are not normally distributed, it may affect the precision of the test. This is especially important for small sample sizes. Transformations or non-parametric alternatives may be considered in case of severe violations.\n",
    "Homogeneity of Variances (Homoscedasticity):\n",
    "\n",
    "Assumption: The variances of the residuals are constant across all levels of the independent variable.\n",
    "Violation Example: If the variances are not equal, it may impact the accuracy of the F-statistic. The presence of unequal variances, also known as heteroscedasticity, can be addressed by using Welch's ANOVA or transforming the data.\n",
    "Additivity and Linearity:\n",
    "\n",
    "Assumption: The relationship between the independent variable and the dependent variable is additive and linear.\n",
    "Violation Example: Non-linear relationships or interactions among factors that are not accounted for in the model can lead to biased results. Checking for interactions and considering non-linear models may be necessary.\n",
    "Random Sampling:\n",
    "\n",
    "Assumption: The samples are randomly and independently selected from the populations.\n",
    "Violation Example: If the samples are not randomly selected or if there is bias in the sampling process, it can affect the generalizability of the results to the broader population.\n",
    "Equal Group Sizes (for One-way ANOVA):\n",
    "\n",
    "Assumption: The groups have equal sample sizes.\n",
    "Violation Example: Unequal group sizes can affect the power of the test, and adjustments may be needed. For unequal group sizes, Welch's ANOVA is an alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?\n",
    "\n",
    "Answer = Analysis of Variance (ANOVA) comes in different types, each designed to address specific experimental designs and research questions. The three main types of ANOVA are:\n",
    "\n",
    "One-way ANOVA:\n",
    "\n",
    "Situation: Used when there is one independent variable (factor) with more than two levels or groups.\n",
    "Example: Comparing the mean scores of three or more groups (treatments, conditions, etc.) to determine if there are any statistically significant differences among them. For instance, comparing the performance of students exposed to different teaching methods.\n",
    "Two-way ANOVA:\n",
    "\n",
    "Situation: Used when there are two independent variables (factors), and the researcher wants to examine the main effects of each factor and the interaction effect between them.\n",
    "Example: Investigating the impact of two factors, such as the effect of a drug (Factor A) and gender (Factor B) on blood pressure. Two-way ANOVA allows the examination of the main effects of the drug and gender, as well as their interaction.\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Situation: Used when measurements are taken on the same subjects or at multiple time points (repeated measurements) under different conditions.\n",
    "Example: Assessing the effect of a treatment over time on the same group of participants. For instance, measuring the blood pressure of individuals before and after treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?\n",
    "\n",
    "Answer  =  The partitioning of variance in Analysis of Variance (ANOVA) refers to the process of decomposing the total variance observed in a dataset into different components that can be attributed to various sources or factors. Understanding this concept is crucial for interpreting the results of ANOVA and gaining insights into the sources of variability in the data.\n",
    "\n",
    "In ANOVA, the total variance observed in the data is partitioned into three main components:\n",
    "\n",
    "Between-Group Variance (SSB or SSBetween):\n",
    "\n",
    "Definition: This component represents the variability among the group means. It measures the extent to which the means of different groups differ from each other.\n",
    "Importance: A large between-group variance suggests that there are significant differences among the group means, supporting the idea that the independent variable has an effect.\n",
    "Within-Group Variance (SSW or SSWithin):\n",
    "\n",
    "Definition: This component represents the variability within each group. It measures the extent to which individual observations within a group deviate from the group mean.\n",
    "Importance: A large within-group variance suggests that there is variability within each group that is not explained by the independent variable. It includes random variability and measurement error.\n",
    "Total Variance (SST or SSTotal):\n",
    "\n",
    "Definition: The overall variability in the entire dataset, representing the sum of the between-group and within-group variances.\n",
    "Importance: Understanding the total variance provides context for assessing the relative size of the between-group and within-group variances. It serves as a baseline against which the explained variance (between groups) can be compared.\n",
    "The partitioning of variance is crucial for the following reasons:\n",
    "\n",
    "Identification of Sources of Variation: It helps identify whether the observed variability in the dependent variable is primarily due to differences between groups or within groups.\n",
    "\n",
    "Calculation of F-Statistic: The ratio of the between-group variance to the within-group variance forms the basis of the F-statistic in ANOVA. This statistic is used to assess whether the differences among group means are statistically significant.\n",
    "\n",
    "Effect Size: Understanding the proportion of total variance explained by the independent variable provides insights into the practical significance or effect size of the observed differences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulated data for demonstration purposes\n",
    "np.random.seed(42)  # For reproducibility\n",
    "group_means = [50, 55, 60]\n",
    "group_sizes = [30, 40, 50]\n",
    "\n",
    "# Generate data assuming normal distribution\n",
    "data = np.concatenate([np.random.normal(mean, 10, size) for mean, size in zip(group_means, group_sizes)])\n",
    "\n",
    "# Calculate overall mean\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate SST\n",
    "sst = np.sum((data - overall_mean)**2)\n",
    "\n",
    "# Calculate SSE\n",
    "sse = np.sum([size * (group_mean - overall_mean)**2 for group_mean, size in zip(group_means, group_sizes)])\n",
    "\n",
    "# Calculate SSR\n",
    "ssr = np.sum([(x - group_mean)**2 for x, group_mean in zip(data, [np.mean(data[i:i+size]) for i, size in enumerate(group_sizes)])])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Total Sum of Squares (SST): {sst}\")\n",
    "print(f\"Explained Sum of Squares (SSE): {sse}\")\n",
    "print(f\"Residual Sum of Squares (SSR): {ssr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Simulated data for demonstration purposes\n",
    "np.random.seed(42)\n",
    "data = pd.DataFrame({\n",
    "    'A': np.random.choice(['A1', 'A2'], size=100),\n",
    "    'B': np.random.choice(['B1', 'B2'], size=100),\n",
    "    'response': np.random.normal(0, 1, size=100)\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('response ~ A + B + A*B', data=data).fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(sm.stats.anova_lm(model, typ=2))\n",
    "\n",
    "# Calculate main effects and interaction effect manually\n",
    "main_effect_A = model.params['A[T.A2]']\n",
    "main_effect_B = model.params['B[T.B2]']\n",
    "interaction_effect = model.params['A[T.A2]:B[T.B2]']\n",
    "\n",
    "# Print the results\n",
    "print(f\"Main Effect of A: {main_effect_A}\")\n",
    "print(f\"Main Effect of B: {main_effect_B}\")\n",
    "print(f\"Interaction Effect: {interaction_effect}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?\n",
    "\n",
    "Answer = In a one-way ANOVA, the F-statistic is used to test whether there are significant differences among the means of three or more groups. The p-value associated with the F-statistic indicates the probability of obtaining such an F-statistic (or more extreme) under the assumption that there are no true differences between the group means. Here's how you can interpret the results:\n",
    "\n",
    "Null Hypothesis (H0): The null hypothesis in ANOVA is that there are no significant differences among the group means.\n",
    "\n",
    "Alternative Hypothesis (H1): The alternative hypothesis is that there are significant differences among the group means.\n",
    "\n",
    "F-Statistic: The F-statistic is a ratio of variances. A larger F-statistic suggests larger differences among group means relative to within-group variability.\n",
    "\n",
    "P-value: The p-value is the probability of observing an F-statistic as extreme as the one obtained, assuming the null hypothesis is true.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "The obtained p-value is 0.02, which is less than the commonly chosen significance level of 0.05.\n",
    "With a p-value of 0.02, you would reject the null hypothesis at the 0.05 significance level.\n",
    "Conclusion:\n",
    "Given the results of the one-way ANOVA:\n",
    "\n",
    "You have evidence to suggest that there are significant differences among the means of the groups.\n",
    "The differences are statistically significant because the p-value is below the chosen significance level.\n",
    "Final Interpretation:\n",
    "\n",
    "The groups being compared in the one-way ANOVA are not likely to have the same population mean. However, the ANOVA itself doesn't tell you which specific groups are different from each other.\n",
    "To identify which groups are different, you might perform post-hoc tests or pairwise comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?\n",
    "\n",
    "Answer = andling missing data in a repeated measures ANOVA is crucial for obtaining valid and reliable results. The method you choose to handle missing data can significantly impact the analysis and subsequent conclusions. Here are common approaches to handle missing data in repeated measures ANOVA and their potential consequences:\n",
    "\n",
    "1. Complete Case Analysis (Listwise Deletion):\n",
    "Handling Method: Exclude cases with missing data.\n",
    "Consequences:\n",
    "Reduces sample size, potentially leading to loss of statistical power.\n",
    "Assumes that missing data are missing completely at random (MCAR), which may not always be realistic.\n",
    "2. Mean Imputation:\n",
    "Handling Method: Replace missing values with the mean of the observed values for that variable.\n",
    "Consequences:\n",
    "Preserves sample size but may distort variability and relationships, especially if the missingness is not completely random.\n",
    "Can lead to biased estimates, particularly when data are not missing completely at random.\n",
    "3. Last Observation Carried Forward (LOCF) or Next Observation Carried Backward (NOCB):\n",
    "Handling Method: Use the last observed value for forward imputation or the next observed value for backward imputation.\n",
    "Consequences:\n",
    "Can introduce bias, especially if there are systematic changes in the variable over time.\n",
    "Assumes that the missing values are constant or gradually changing.\n",
    "4. Interpolation or Linear Regression Imputation:\n",
    "Handling Method: Use interpolation or regression to estimate missing values based on observed values.\n",
    "Consequences:\n",
    "Assumes a linear relationship between the observed values, which may not be accurate in all cases.\n",
    "Results may be sensitive to the assumed relationships.\n",
    "5. Multiple Imputation:\n",
    "Handling Method: Generate multiple imputed datasets, analyze each separately, and combine results.\n",
    "Consequences:\n",
    "Preserves sample size and accounts for uncertainty in imputations.\n",
    "Requires additional computational resources.\n",
    "Assumes that data are missing at random (MAR), conditional on observed variables.\n",
    "6. Maximum Likelihood Estimation (MLE):\n",
    "Handling Method: Estimates parameters while accounting for missing data using likelihood-based methods.\n",
    "Consequences:\n",
    "Preserves sample size and provides unbiased estimates under the MAR assumption.\n",
    "May be computationally intensive.\n",
    "Potential Pitfalls and Considerations:\n",
    "Bias: Most imputation methods introduce some level of bias, and the choice of method should be based on the assumptions that best fit the data.\n",
    "Assumption Checks: Regardless of the method chosen, it's crucial to check the assumption of missing data mechanisms (MCAR, MAR) to assess the appropriateness of the chosen approach.\n",
    "Sensitivity Analysis: Perform sensitivity analyses to evaluate the impact of different imputation methods on results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary.\n",
    "\n",
    "Answer = Post-hoc tests are used in the context of Analysis of Variance (ANOVA) to make pairwise comparisons between group means when the overall ANOVA test indicates that there are significant differences among at least three groups. Common post-hoc tests help identify which specific groups differ from each other. Here are some common post-hoc tests and situations where they might be used:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD):\n",
    "Use Case:\n",
    "When you have equal sample sizes and you want to control the familywise error rate.\n",
    "Example:\n",
    "In a study comparing the mean scores of three different teaching methods, the overall ANOVA indicates significant differences. Tukey's HSD can be used to identify which specific pairs of teaching methods are significantly different.\n",
    "2. Bonferroni Correction:\n",
    "Use Case:\n",
    "When you want to control the familywise error rate, but sample sizes may be unequal.\n",
    "Example:\n",
    "In a drug trial comparing the effects of four different dosages, the overall ANOVA suggests differences. Bonferroni correction can be applied to assess pairwise differences while controlling for the increased risk of Type I error due to multiple comparisons.\n",
    "3. Holm's Method:\n",
    "Use Case:\n",
    "Similar to Bonferroni, but potentially more powerful when some of the comparisons are expected to be non-significant.\n",
    "Example:\n",
    "In a study comparing the performance of three different age groups, Holm's method can be used to control the familywise error rate while considering the expected pattern of differences.\n",
    "4. Scheffé's Test:\n",
    "Use Case:\n",
    "When sample sizes are unequal, and you want to control the familywise error rate.\n",
    "Example:\n",
    "In a study comparing the effects of four different diets on weight loss, with unequal sample sizes in each diet group, Scheffé's test can be used for pairwise comparisons.\n",
    "5. Dunnett's Test:\n",
    "Use Case:\n",
    "When you have a control group, and you want to compare other groups to the control while controlling the familywise error rate.\n",
    "Example:\n",
    "In a clinical trial with a control group receiving a placebo and three experimental groups receiving different treatments, Dunnett's test can be used to compare each experimental group to the control.\n",
    "6. Games-Howell Test:\n",
    "Use Case:\n",
    "When sample sizes are unequal, and assumptions of equal variances are violated.\n",
    "Example:\n",
    "In a study comparing the performance of several different brands of a product with varying sample sizes and unequal variances, Games-Howell test can be used for pairwise comparisons.\n",
    "Example Situation:\n",
    "Consider a scenario where a researcher conducts an ANOVA to compare the mean scores of four different exercise programs (A, B, C, D) on weight loss. The overall ANOVA indicates a significant difference among the groups. A post-hoc test (e.g., Tukey's HSD) would be used to compare specific pairs of exercise programs and identify which ones result in significantly different weight loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Simulated data for demonstration purposes\n",
    "np.random.seed(42)  # For reproducibility\n",
    "data_A = np.random.normal(2, 1, 50)  # Mean weight loss for diet A\n",
    "data_B = np.random.normal(3, 1, 50)  # Mean weight loss for diet B\n",
    "data_C = np.random.normal(2.5, 1, 50)  # Mean weight loss for diet C\n",
    "\n",
    "# Concatenate data for one-way ANOVA\n",
    "data_all = np.concatenate([data_A, data_B, data_C])\n",
    "\n",
    "# Create corresponding group labels\n",
    "groups = ['A'] * 50 + ['B'] * 50 + ['C'] * 50\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(data_A, data_B, data_C)\n",
    "\n",
    "# Print the results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Simulated data for demonstration purposes\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate data\n",
    "data = pd.DataFrame({\n",
    "    'Software': np.random.choice(['A', 'B', 'C'], size=90),\n",
    "    'Experience': np.random.choice(['Novice', 'Experienced'], size=90),\n",
    "    'Time': np.random.normal(10, 2, 90)  # Adjust mean and standard deviation as needed\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Time ~ Software * Experience', data=data).fit()\n",
    "\n",
    "# Print the ANOVA table\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "print(\"\\nInterpretation:\")\n",
    "if anova_table['PR(>F)']['Software'] < alpha:\n",
    "    print(\"Reject the null hypothesis for the main effect of Software.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for the main effect of Software.\")\n",
    "\n",
    "if anova_table['PR(>F)']['Experience'] < alpha:\n",
    "    print(\"Reject the null hypothesis for the main effect of Experience.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for the main effect of Experience.\")\n",
    "\n",
    "if anova_table['PR(>F)']['Software:Experience'] < alpha:\n",
    "    print(\"Reject the null hypothesis for the interaction effect between Software and Experience.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis for the interaction effect between Software and Experience.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.stats.multitest as smm\n",
    "\n",
    "# Simulated data for demonstration purposes\n",
    "np.random.seed(42)  # For reproducibility\n",
    "control_group = np.random.normal(70, 10, 100)  # Control group (traditional teaching method)\n",
    "experimental_group = np.random.normal(75, 10, 100)  # Experimental group (new teaching method)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print the results of the t-test\n",
    "print(f\"Two-Sample T-Test:\")\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Check if the results are significant\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The results of the two-sample t-test are significant.\")\n",
    "    \n",
    "    # Perform post-hoc tests (if needed)\n",
    "    # Example: Bonferroni correction for multiple comparisons\n",
    "    _, p_values_corrected, _, _ = smm.multipletests([p_value], alpha=alpha, method='bonferroni')\n",
    "    \n",
    "    print(\"\\nPost-Hoc Test:\")\n",
    "    if p_values_corrected[0] < alpha:\n",
    "        print(\"There is a significant difference between the control and experimental groups.\")\n",
    "    else:\n",
    "        print(\"There is no significant difference between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"The results of the two-sample t-test are not significant. No post-hoc test is performed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Simulated data for demonstration purposes\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Generate data\n",
    "data_A = np.random.normal(1000, 100, 30)  # Daily sales for Store A\n",
    "data_B = np.random.normal(1200, 120, 30)  # Daily sales for Store B\n",
    "data_C = np.random.normal(1100, 110, 30)  # Daily sales for Store C\n",
    "\n",
    "# Concatenate data for one-way ANOVA\n",
    "data_all = np.concatenate([data_A, data_B, data_C])\n",
    "\n",
    "# Create corresponding group labels\n",
    "groups = ['A'] * 30 + ['B'] * 30 + ['C'] * 30\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(data_A, data_B, data_C)\n",
    "\n",
    "# Print the results\n",
    "print(f\"One-way ANOVA:\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Check if the results are significant\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nThe results of the one-way ANOVA are significant.\")\n",
    "\n",
    "    # Perform post-hoc Tukey's HSD test\n",
    "    posthoc = pairwise_tukeyhsd(data_all, groups)\n",
    "    print(\"\\nPost-Hoc Test:\")\n",
    "    print(posthoc)\n",
    "else:\n",
    "    print(\"\\nThe results of the one-way ANOVA are not significant. No post-hoc test is performed.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
